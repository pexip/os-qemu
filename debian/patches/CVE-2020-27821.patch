From: Paolo Bonzini <pbonzini@redhat.com>
Date: Sun, 18 Mar 2018 17:26:36 +0000 (+0100)
Subject: exec: reintroduce MemoryRegion caching
X-Git-Tag: v3.0.0-rc0~163^2~19
X-Git-Url: https://git.qemu.org/?p=qemu.git;a=commitdiff_plain;h=48564041a73adbbff52834f9edbe3806fceefab7

exec: reintroduce MemoryRegion caching

MemoryRegionCache was reverted to "normal" address_space_* operations
for 2.9, due to lack of support for IOMMUs.  Reinstate the
optimizations, caching only the IOMMU translation at address_cache_init
but not the IOMMU lookup and target AddressSpace translation are not
cached; now that MemoryRegionCache supports IOMMUs, it becomes more widely
applicable too.

The inlined fast path is defined in memory_ldst_cached.inc.h, while the
slow path uses memory_ldst.inc.c as before.  The smaller fast path causes
a little code size reduction in MemoryRegionCache users:

    hw/virtio/virtio.o text size before: 32373
    hw/virtio/virtio.o text size after: 31941

Signed-off-by: Paolo Bonzini <pbonzini@redhat.com>
--- qemu-3.1+dfsg.orig/exec.c
+++ qemu-3.1+dfsg/exec.c
@@ -3723,6 +3723,7 @@ int64_t address_space_cache_init(MemoryR
     AddressSpaceDispatch *d;
     hwaddr l;
     MemoryRegion *mr;
+    Int128 diff;
 
     assert(len > 0);
 
@@ -3731,6 +3732,16 @@ int64_t address_space_cache_init(MemoryR
     d = flatview_to_dispatch(cache->fv);
     cache->mrs = *address_space_translate_internal(d, addr, &cache->xlat, &l, true);
 
+    /*
+     * cache->xlat is now relative to cache->mrs.mr, not to the section itself.
+     * Take that into account to compute how many bytes are there between
+     * cache->xlat and the end of the section.
+     */
+    diff = int128_sub(cache->mrs.size,
+                     int128_make64(cache->xlat - cache->mrs.offset_within_region));
+    l = int128_get64(int128_min(diff, int128_make64(l)));
+
+
     mr = cache->mrs.mr;
     memory_region_ref(mr);
     if (memory_access_is_direct(mr, is_write)) {
